{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STATISTICS IN NUMPY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEAN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The first statistical concept we’ll explore is mean, also commonly referred to as an average. The mean is a useful measurement to get the center of a dataset. NumPy has a built-in function to calculate the average or mean of arrays: np.mean\n",
    "\n",
    "We can then transform the dataset into a NumPy array and use the function np.mean to calculate the average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean is 6.5\n",
      "The mean is 10.428571428571429\n",
      "The mean is 5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "store_one = np.array([2, 5, 8, 3, 4, 10, 15, 5])\n",
    "store_two = np.array([3, 17, 18,  9,  2, 14, 10])\n",
    "store_three = np.array([7, 5, 4, 3, 2, 7, 7])\n",
    "\n",
    "store_one_avg = np.mean(store_one)\n",
    "store_two_avg = np.mean(store_two)\n",
    "store_three_avg = np.mean(store_three)\n",
    "stores_mean = [store_one_avg, store_two_avg, store_three_avg]\n",
    "\n",
    "for mean in stores_mean:\n",
    "    print(\"The mean is {}\".format(mean))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can also use np.mean to calculate the percent of array elements that have a certain property.\n",
    "\n",
    "As we know, a logical operator will evaluate each item in an array to see if it matches the specified condition. If the item matches the given condition, the item will evaluate as True and equal 1. If it does not match, it will be False and equal 0.\n",
    "\n",
    "When np.mean calculates a logical statement, the resulting mean value will be equivalent to the total number of True items divided by the total array length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.0%\n"
     ]
    }
   ],
   "source": [
    "class_year = np.array([1967, 1949, 2004, 1997, 1953, 1950, 1958, 1974, 1987, 2006, 2013, 1978, 1951, 1998, 1996, 1952, 2005, 2007, 2003, 1955, 1963, 1978, 2001, 2012, 2014, 1948, 1970, 2011, 1962, 1966, 1978, 1988, 2006, 1971, 1994, 1978, 1977, 1960, 2008, 1965, 1990, 2011, 1962, 1995, 2004, 1991, 1952, 2013, 1983, 1955, 1957, 1947, 1994, 1978, 1957, 2016, 1969, 1996, 1958, 1994, 1958, 2008, 1988, 1977, 1991, 1997, 2009, 1976, 1999, 1975, 1949, 1985, 2001, 1952, 1953, 1949, 2015, 2006, 1996, 2015, 2009, 1949, 2004, 2010, 2011, 2001, 1998, 1967, 1994, 1966, 1994, 1986, 1963, 1954, 1963, 1987, 1992, 2008, 1979, 1987])\n",
    "millenials = np.mean(class_year > 2004)\n",
    "print(\"{}%\".format(millenials*100))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "If we have a two-dimensional array, np.mean can calculate the means of the larger array as well as the interior values.\n",
    "\n",
    "Let’s imagine a game of ring toss at a carnival. In this game, you have three different chances to get all three rings onto a stick. In our ring_toss array, each interior array (the arrays within the larger array) is one try, and each number is one ring toss. 1 represents a successful toss, 0 represents a fail.\n",
    "\n",
    "First, we can use np.mean to find the mean across all the arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean across the array is equal to 0.4444444444444444\n"
     ]
    }
   ],
   "source": [
    "ring_toss = np.array([[1, 0, 0], \n",
    "                     [0, 0, 1], \n",
    "                     [1, 0, 1]])\n",
    "print(\"The mean across the array is equal to {}\".format(np.mean(ring_toss)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To find the means of each interior array, we specify axis 1 (the “rows”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means of the rows are equal to [0.33333333 0.33333333 0.66666667]\n"
     ]
    }
   ],
   "source": [
    "print(\"The means of the rows are equal to {}\".format(np.mean(ring_toss, axis=1)))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To find the means of each index position (i.e, mean of all 1st tosses, mean of all 2nd tosses, …), we specify axis 0 (the “columns”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The means of the columns are equal to [0.66666667 0.         0.66666667]\n"
     ]
    }
   ],
   "source": [
    "print(\"The means of the columns are equal to {}\".format(np.mean(ring_toss, axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUTLIERS"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Values that don’t fit within the majority of a dataset are known as outliers. It’s important to identify outliers because if they go unnoticed, they can skew our data and lead to error in our analysis (like determining the mean). They can also be useful in pointing out errors in our data collection.\n",
    "\n",
    "When we’re able to identify outliers, we can then determine if they were due to an error in sample collection or whether or not they represent a significant but real deviation from the mean.\n",
    "\n",
    "One way to quickly identify outliers is by sorting our data, Once our data is sorted, we can quickly glance at the beginning or end of an array to see if some values lie far beyond the expected range. We can use the NumPy function np.sort to sort our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199 198 196 195 191 187 101 101 100  99  99  99  99  99  98  98  98  98\n",
      "  98  98  97  97  97  97  97  96  96  96  96  96  96  95  95  94  94  94\n",
      "  94  94  94  94  93  93  93  93  93  92  92  92  92  92  91  91  91  90\n",
      "  90  90  90  90  90  90  90  89  89  88  88  88  88  88  88  88  88  87\n",
      "  87  87  87  87  87  87  86  86  86  86  86  86  86  85  85  85  85  85]\n",
      "\n",
      "\n",
      "We noticed that those values are outliers : [187 191 195 196 198 199]\n"
     ]
    }
   ],
   "source": [
    "temps = np.array([86, 88, 94, 85, 97, 90, 87, 85, 94, 93, 92, 95, 98, 85, 94, 91, 97, 88, 87, 86, 99, 89, 89, 99, 88, 96, 93, 96, 85, 88, 191, 95, 96, 87, 99, 93, 90, 86, 87, 100, 187, 98, 101, 101, 96, 94, 96, 87, 86, 92, 98,94, 98, 90, 99, 96, 99, 86, 97, 98, 86, 90, 86, 94, 91, 88, 196, 195,93, 97, 199, 87, 87, 90, 90, 98, 88, 92, 97, 88, 85, 94, 88, 93, 198, 90, 91, 90, 92, 92])\n",
    "\n",
    "sorted_temps = np.sort(temps)\n",
    "reversed_temps = sorted_temps[::-1]\n",
    "print(reversed_temps)\n",
    "print(\"\\n\")\n",
    "print(\"We noticed that those values are outliers : [187 191 195 196 198 199]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEDIAN"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Another key metric that we can use in data analysis is the median. The median is the middle value of a dataset that’s been ordered in terms of magnitude (from lowest to highest).\n",
    "\n",
    "In a dataset, the median value can provide an important comparison to the mean. Unlike a mean, the median is not affected by outliers. This becomes important in skewed datasets, datasets whose values are not distributed evenly.\n",
    "\n",
    "This value is also known as the 50th percentile, which means that 50% of the data is less than it, and the other 50% is greater than it.\n",
    "\n",
    "If the length of our dataset was an even number, the median would be the value halfway between the two central values.\n",
    "\n",
    "NumPy also has a function to calculate the median, np.median:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The median for the dataset 'nums' is 3.5.\n"
     ]
    }
   ],
   "source": [
    "nums = np.array( [1, 1, 2, 3, 4, 5, 5, 6])\n",
    "nums_median = np.median(nums)\n",
    "print(\"The median for the dataset 'nums' is {}.\".format(nums_median))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PERCENTILES"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The Nth percentile is defined as the point N% of samples lie below it. So the point where 40% of samples are below is called the 40th percentile. Percentiles are useful measurements because they can tell us where a particular value is situated within the greater dataset.\n",
    "\n",
    "The 25th percentile is called the first quartile.\n",
    "The 50th percentile is called the median.\n",
    "The 75th percentile is called the third quartile.\n",
    "\n",
    "The minimum, first quartile, median, third quartile, and maximum of a dataset are called a five-number summary. This set of numbers is a great thing to compute when we get a new dataset.\n",
    "\n",
    "In NumPy, we can calculate percentiles using the function np.percentile, which takes two arguments: the array and the percentile to calculate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The thirtieth percentile is 3.0.\n",
      "The seventieth percentile is 8.0.\n"
     ]
    }
   ],
   "source": [
    "patrons = np.array([ 2, 6, 14, 4, 3, 9, 1, 11, 4, 2, 8])\n",
    "\n",
    "thirtieth_percentile = np.percentile(patrons, 30)\n",
    "seventieth_percentile = np.percentile(patrons, 70)\n",
    "\n",
    "print(\"The thirtieth percentile is {}.\".format(thirtieth_percentile))\n",
    "print(\"The seventieth percentile is {}.\".format(seventieth_percentile))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "To find the interquartile range, it's necessary to compute the first quartile and the third quartile, and subtract the value of the 25th percentile from the value of the 75th.\n",
    "\n",
    "50% of the dataset will lie within the interquartile range. The interquartile range gives us an idea of how spread out our data is. The smaller the interquartile range value, the less variance in our dataset. The greater the value, the larger the variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first quartile :1.0\n",
      "third quartile :3.5\n",
      "interquartile range :2.5\n"
     ]
    }
   ],
   "source": [
    "movies_watched = np.array([2, 3, 8, 0, 2, 4, 3, 1, 1, 0, 5, 1, 1, 7, 2])\n",
    "\n",
    "first_quarter = np.percentile(movies_watched, 25)\n",
    "third_quarter = np.percentile(movies_watched, 75)\n",
    "interquartile_range = third_quarter - first_quarter\n",
    "\n",
    "print('first quartile :{}'.format(first_quarter)) \n",
    "print('third quartile :{}'.format(third_quarter)) \n",
    "print('interquartile range :{}'.format(interquartile_range))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STANDARD DEVIATION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "While the mean and median can tell us about the center of our data, they do not reflect the range of the data. That’s where standard deviation comes in.\n",
    "\n",
    "Similar to the interquartile range, the standard deviation tells us the spread of the data. The larger the standard deviation, the more spread out our data is from the center. The smaller the standard deviation, the more the data is clustered around the mean.\n",
    "\n",
    "We can find the standard deviation of a dataset using the Numpy function np.std:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation for the pumpkin dataset is 611.3183785884406.\n",
      "The standard deviation for the acorn squash dataset is 87.22505374031019.\n"
     ]
    }
   ],
   "source": [
    "pumpkin = np.array([68, 1820, 1420, 2062, 704, 1156, 1857, 1755, 2092, 1384])\n",
    "\n",
    "acorn_squash = np.array([20, 43, 99, 200, 12, 250, 58, 120, 230, 215])\n",
    "\n",
    "pumpkin_avg = np.mean(pumpkin)\n",
    "acorn_squash_avg = np.mean(acorn_squash)\n",
    "\n",
    "pumpkin_std = np.std(pumpkin)\n",
    "acorn_squash_std = np.std(acorn_squash)\n",
    "\n",
    "print(\"The standard deviation for the pumpkin dataset is {}.\".format(pumpkin_std))\n",
    "print(\"The standard deviation for the acorn squash dataset is {}.\".format(acorn_squash_std))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
